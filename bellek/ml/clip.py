# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/ml.clip.ipynb.

# %% auto 0
__all__ = ['load_clip_preprocess', 'make_tfms_from_clip_preprocess', 'ClipZeroShotClassifier']

# %% ../../nbs/ml.clip.ipynb 3
import clip
import torch
import torch.nn as nn
from torchvision import transforms
from .vision import TorchVisionTransform

# %% ../../nbs/ml.clip.ipynb 4
def load_clip_preprocess(clip_model_name):
    from clip import clip
    return clip.load(clip_model_name, device='cpu')[1]


# %% ../../nbs/ml.clip.ipynb 5
def make_tfms_from_clip_preprocess(clip_preprocess):
    item_tfms = TorchVisionTransform(transforms.Compose(clip_preprocess.transforms[:-2]))
    batch_tfms = TorchVisionTransform(transforms.Compose(clip_preprocess.transforms[-2:]))
    return item_tfms, batch_tfms

# %% ../../nbs/ml.clip.ipynb 6
class ClipZeroShotClassifier(nn.Module):
    def __init__(self, clip_model, class_descriptions):
        super().__init__()
        self.clip_model = clip_model
        with torch.inference_mode():
            text_tokens = clip.tokenize(class_descriptions)
            text_features = clip_model.encode_text(text_tokens).float()
            text_features = text_features / text_features.norm(dim=-1, keepdim=True)
        self.text_features = nn.Parameter(text_features.cpu(), requires_grad=False)
    
    def forward(self, image):
        image_features = self.clip_model.encode_image(image.type(self.clip_model.dtype))
        image_features = image_features / image_features.norm(dim=-1, keepdim=True)
        logits = image_features @ self.text_features.T
        return logits
