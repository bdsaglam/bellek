{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bellek.text.utils import fuzzy_match\n",
    "from bellek.utils import set_seed, jprint\n",
    "\n",
    "set_seed(89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbdsaglam\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/bdsaglam/dev/repos/bellek/dev_nbs/musique-kg-llm/wandb/run-20240113_161128-a4hzjcih</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/bdsaglam/thesis-mhqa-baseline-context-langchain/runs/a4hzjcih' target=\"_blank\">wild-wind-5</a></strong> to <a href='https://wandb.ai/bdsaglam/thesis-mhqa-baseline-context-langchain' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bdsaglam/thesis-mhqa-baseline-context-langchain' target=\"_blank\">https://wandb.ai/bdsaglam/thesis-mhqa-baseline-context-langchain</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bdsaglam/thesis-mhqa-baseline-context-langchain/runs/a4hzjcih' target=\"_blank\">https://wandb.ai/bdsaglam/thesis-mhqa-baseline-context-langchain/runs/a4hzjcih</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import wandb\n",
    "from bellek.langchain.obs import patch_wandb_tracer_serialize_io\n",
    "from bellek.wandb import generate_run_id\n",
    "\n",
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"thesis-mhqa-baseline-context-langchain\"\n",
    "os.environ[\"WANDB_RUN_ID\"] = generate_run_id(8)\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = os.path.basename(globals()['__vsc_ipynb_file__'])\n",
    "os.environ[\"WANDB_NOTES\"] = \"Model sees only question\"\n",
    "\n",
    "patch_wandb_tracer_serialize_io()\n",
    "\n",
    "wandb_run = wandb.init(project=os.environ[\"WANDB_PROJECT\"], resume=os.environ[\"WANDB_RUN_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_aliases</th>\n",
       "      <th>answerable</th>\n",
       "      <th>question</th>\n",
       "      <th>question_decomposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2hop__128801_205185</td>\n",
       "      <td>[{'idx': 0, 'title': 'Pama, Burkina Faso', 'pa...</td>\n",
       "      <td>Midland County</td>\n",
       "      <td>[Midland County, Texas]</td>\n",
       "      <td>True</td>\n",
       "      <td>What county is the town where KNFM is licensed...</td>\n",
       "      <td>[{'question': 'Which town is KNFM licensed in?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2hop__719559_217649</td>\n",
       "      <td>[{'idx': 0, 'title': 'Antoine Marchand', 'para...</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>What's the record label of the artist who put ...</td>\n",
       "      <td>[{'question': 'Who is the artist behind the so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2hop__128806_205185</td>\n",
       "      <td>[{'idx': 0, 'title': 'Spanish Town', 'paragrap...</td>\n",
       "      <td>Midland County</td>\n",
       "      <td>[Midland County, Texas]</td>\n",
       "      <td>True</td>\n",
       "      <td>What region is the town where KQRX is liscense...</td>\n",
       "      <td>[{'question': 'In which town is KQRX licensed?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2hop__837090_278127</td>\n",
       "      <td>[{'idx': 0, 'title': 'The Opening (album)', 'p...</td>\n",
       "      <td>Roc-A-Fella Records</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>What is the record label of the Do It Again pe...</td>\n",
       "      <td>[{'question': 'Who is the performer of the son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2hop__128895_11424</td>\n",
       "      <td>[{'idx': 0, 'title': 'Ehrhardt, South Carolina...</td>\n",
       "      <td>15,504</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>How many households were there in the town WPU...</td>\n",
       "      <td>[{'question': 'In which town is WPUR licensed?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         paragraphs  \\\n",
       "0  2hop__128801_205185  [{'idx': 0, 'title': 'Pama, Burkina Faso', 'pa...   \n",
       "1  2hop__719559_217649  [{'idx': 0, 'title': 'Antoine Marchand', 'para...   \n",
       "2  2hop__128806_205185  [{'idx': 0, 'title': 'Spanish Town', 'paragrap...   \n",
       "3  2hop__837090_278127  [{'idx': 0, 'title': 'The Opening (album)', 'p...   \n",
       "4   2hop__128895_11424  [{'idx': 0, 'title': 'Ehrhardt, South Carolina...   \n",
       "\n",
       "                answer           answer_aliases  answerable  \\\n",
       "0       Midland County  [Midland County, Texas]        True   \n",
       "1         Warner Bros.                       []        True   \n",
       "2       Midland County  [Midland County, Texas]        True   \n",
       "3  Roc-A-Fella Records                       []        True   \n",
       "4               15,504                       []        True   \n",
       "\n",
       "                                            question  \\\n",
       "0  What county is the town where KNFM is licensed...   \n",
       "1  What's the record label of the artist who put ...   \n",
       "2  What region is the town where KQRX is liscense...   \n",
       "3  What is the record label of the Do It Again pe...   \n",
       "4  How many households were there in the town WPU...   \n",
       "\n",
       "                              question_decomposition  \n",
       "0  [{'question': 'Which town is KNFM licensed in?...  \n",
       "1  [{'question': 'Who is the artist behind the so...  \n",
       "2  [{'question': 'In which town is KQRX licensed?...  \n",
       "3  [{'question': 'Who is the performer of the son...  \n",
       "4  [{'question': 'In which town is WPUR licensed?...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df = pd.read_json('../../data/generated/musique-kg-llm/train/dataset.jsonl', orient='records', lines=True)\n",
    "qd_df = pd.read_json('../../data/generated/musique-kg-llm/train/question-decomposition.jsonl', orient='records', lines=True)\n",
    "df = pd.merge(ds_df.drop(columns=['question', 'question_decomposition']), qd_df, on='id', suffixes=('', ''))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_docs(example, only_supporting=False):\n",
    "    ps = example[\"paragraphs\"]\n",
    "    for p in ps:\n",
    "        if only_supporting and not p[\"is_supporting\"]:\n",
    "            continue\n",
    "        idx = p[\"idx\"]\n",
    "        title = p[\"title\"]\n",
    "        body = p[\"paragraph_text\"]\n",
    "        is_supporting = p[\"is_supporting\"]\n",
    "        text = f\"# {title}\\n{body}\"\n",
    "        yield dict(\n",
    "            text=text,\n",
    "            metadata={\"parent_id\": example[\"id\"], \"idx\": idx, \"is_supporting\": is_supporting},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_example(example, predicted_answer):\n",
    "    text = \"\\n\\n\".join([p[\"paragraph_text\"] for p in example['paragraphs']])\n",
    "    print(\"=\"*80)\n",
    "    print(\"Question:\", example[\"question\"])\n",
    "    print(\"Reference Answer:\", example['answer'])\n",
    "    print(\"Predicted Answer:\", predicted_answer)\n",
    "    print(\"-\"*80)\n",
    "    print(\"Paragraphs\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bdsaglam/dev/repos/bellek/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use langchain_openai.ChatOpenAI instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.openai_functions import create_structured_output_runnable\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert Q&A system that is trusted around the world. You are given a question that requires multi-hop reasoning. Always answer the query using the provided context information, and not prior knowledge.\n",
    "Some rules to follow:\n",
    "1. Never directly reference the given context in your answer.\n",
    "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
    "3. Your answer must be 2-4 words long.\"\"\"\n",
    "\n",
    "USER_PROMPT = \"\"\"Context information is below.\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the question.\n",
    "{query_str}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SYSTEM_PROMPT), \n",
    "    (\"user\", USER_PROMPT),\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "class Output(BaseModel):\n",
    "    \"\"\"Output containing the answers for questions.\"\"\"\n",
    "    answer: str\n",
    "    reasoning: str = Field(description=\"Multi-hop reasoning for the answer.\")\n",
    "\n",
    "chain = create_structured_output_runnable(Output, llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_question(example):\n",
    "    return example['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(example):\n",
    "    documents = list(make_docs(example, only_supporting=False))\n",
    "    context = \"\\n\\n\".join([doc[\"text\"] for doc in documents])\n",
    "    output = chain.invoke({\"context_str\": context, \"query_str\": format_question(example)}).dict()\n",
    "    example['predicted_answer'] = output.get(\"answer\")\n",
    "    example['raw_llm_output'] = output\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_answer(example):\n",
    "    try:\n",
    "        return answer(example)\n",
    "    except Exception as exc:\n",
    "        id = example['id']\n",
    "        print(f\"Failed to answer the question {id}\\n{exc}\")\n",
    "        example['predicted_answer'] = None\n",
    "        example['raw_llm_output'] = None\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.globals import set_debug\n",
    "# set_debug(True)\n",
    "\n",
    "# i = 0\n",
    "# example = df.iloc[i].to_dict()\n",
    "# example_ = answer(example)\n",
    "# print(\"Question:\", example['question'])\n",
    "# print(\"Reference answer:\", example['answer'])\n",
    "# print(\"Predicted answer:\", example_['predicted_answer'])\n",
    "\n",
    "# print(\"-\"*20)\n",
    "# jprint(example_['raw_llm_output'])\n",
    "\n",
    "# set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(safe_answer, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _exact_match(example):\n",
    "    pred, ref = example['predicted_answer'], example['answer']\n",
    "    return pred is not None and pred == ref\n",
    "\n",
    "def _fuzzy_match(example):\n",
    "    pred, ref = example['predicted_answer'], example['answer']\n",
    "    return pred is not None and ((pred in ref) or (ref in pred) or fuzzy_match(pred, ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'exact_match': 0.41, 'fuzzy_match': 0.61}\n"
     ]
    }
   ],
   "source": [
    "df[\"exact_match\"] = df.apply(_exact_match, axis=1)\n",
    "df[\"fuzzy_match\"] = df.apply(_fuzzy_match, axis=1)\n",
    "\n",
    "# log scores\n",
    "scores = {\n",
    "    \"exact_match\": df[\"exact_match\"].mean(),\n",
    "    \"fuzzy_match\": df[\"fuzzy_match\"].mean(),\n",
    "}\n",
    "print(scores)\n",
    "wandb_run.log(scores)\n",
    "\n",
    "# log evaluation results\n",
    "cols_to_keep = ['id', 'question', 'question_decomposition', 'answer', 'answer_aliases', 'predicted_answer', 'exact_match', 'fuzzy_match', 'raw_llm_output']\n",
    "eval_table = wandb.Table(dataframe=df[cols_to_keep])\n",
    "wandb_run.log({\n",
    "    \"evaluation-table\": eval_table,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ccae25f90014d0d82ca5dc5cb70581c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.183 MB of 0.183 MB uploaded (0.022 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING No requirements.txt found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 8.7%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>exact_match</td><td>▁</td></tr><tr><td>fuzzy_match</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>exact_match</td><td>0.41</td></tr><tr><td>fuzzy_match</td><td>0.61</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wild-wind-5</strong> at: <a href='https://wandb.ai/bdsaglam/thesis-mhqa-baseline-context-langchain/runs/a4hzjcih' target=\"_blank\">https://wandb.ai/bdsaglam/thesis-mhqa-baseline-context-langchain/runs/a4hzjcih</a><br/>Synced 3 W&B file(s), 1 media file(s), 6 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240113_161128-a4hzjcih/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# finish run\n",
    "wandb_run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
