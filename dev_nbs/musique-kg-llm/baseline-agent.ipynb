{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-hop question answering with agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bdsaglam/knowledge/bellek/.venv/lib/python3.10/site-packages/pydantic/_internal/_config.py:219: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.1.1/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n",
      "/Users/bdsaglam/knowledge/bellek/.venv/lib/python3.10/site-packages/litellm/proxy/_types.py:83: PydanticDeprecatedSince20: `pydantic.config.Extra` is deprecated, use literal values instead (e.g. `extra='allow'`). Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.1.1/migration/\n",
      "  extra = Extra.allow  # Allow extra fields\n",
      "/Users/bdsaglam/knowledge/bellek/.venv/lib/python3.10/site-packages/litellm/proxy/_types.py:86: PydanticDeprecatedSince20: Pydantic V1 style `@root_validator` validators are deprecated. You should migrate to Pydantic V2 style `@model_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.1.1/migration/\n",
      "  @root_validator(pre=True)\n",
      "/Users/bdsaglam/knowledge/bellek/.venv/lib/python3.10/site-packages/litellm/proxy/_types.py:111: PydanticDeprecatedSince20: Pydantic V1 style `@root_validator` validators are deprecated. You should migrate to Pydantic V2 style `@model_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.1.1/migration/\n",
      "  @root_validator(pre=True)\n",
      "/Users/bdsaglam/knowledge/bellek/.venv/lib/python3.10/site-packages/wandb/env.py:16: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  from distutils.util import strtobool\n",
      "/Users/bdsaglam/knowledge/bellek/.venv/lib/python3.10/site-packages/umap/__init__.py:9: ImportWarning: Tensorflow not installed; ParametricUMAP will be unavailable\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import weaviate\n",
    "from pydantic import BaseModel\n",
    "from llama_index import Document, ServiceContext\n",
    "from llama_index.prompts.base import Prompt\n",
    "from llama_index.prompts.prompt_type import PromptType\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.vector_stores import WeaviateVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "from llama_index.llms import ChatMessage, LiteLLM, LangChainLLM, OpenAI\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.agent import OpenAIAgent\n",
    "from llama_index.tools.function_tool import FunctionTool\n",
    "from llama_index.callbacks import CallbackManager, LlamaDebugHandler\n",
    "\n",
    "from bellek.llama_index.obs import make_phoenix_trace_callback_handler\n",
    "from bellek.text.utils import fuzzy_match\n",
    "from bellek.utils import generate_time_id, set_seed\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoenix_handler = make_phoenix_trace_callback_handler(Path(f\"/tmp/phoenix/thesis-kg-llm/baseline-agent/traces-{generate_time_id()}.jsonl\"))\n",
    "callback_manager = CallbackManager(handlers=[\n",
    "    phoenix_handler,\n",
    "    # LlamaDebugHandler(print_trace_on_end=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo\", \n",
    "    temperature=0,\n",
    "    api_base=\"http://localhost:11000/\",\n",
    ")\n",
    "embed_model = HuggingFaceEmbedding(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, \n",
    "    embed_model=embed_model,\n",
    "    callback_manager=callback_manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_aliases</th>\n",
       "      <th>answerable</th>\n",
       "      <th>text</th>\n",
       "      <th>question</th>\n",
       "      <th>question_decomposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2hop__128801_205185</td>\n",
       "      <td>[{'idx': 0, 'title': 'Pama, Burkina Faso', 'pa...</td>\n",
       "      <td>Midland County</td>\n",
       "      <td>[Midland County, Texas]</td>\n",
       "      <td>True</td>\n",
       "      <td>Pama is a town located in the province of Komp...</td>\n",
       "      <td>What county is the town where KNFM is licensed...</td>\n",
       "      <td>[{'question': 'In which town is KNFM licensed?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2hop__719559_217649</td>\n",
       "      <td>[{'idx': 0, 'title': 'Antoine Marchand', 'para...</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>Antoine Marchand is a record label established...</td>\n",
       "      <td>What's the record label of the artist who put ...</td>\n",
       "      <td>[{'question': 'Who is the artist who released ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2hop__128806_205185</td>\n",
       "      <td>[{'idx': 0, 'title': 'Spanish Town', 'paragrap...</td>\n",
       "      <td>Midland County</td>\n",
       "      <td>[Midland County, Texas]</td>\n",
       "      <td>True</td>\n",
       "      <td>Spanish Town is the capital and the largest to...</td>\n",
       "      <td>What region is the town where KQRX is liscense...</td>\n",
       "      <td>[{'question': 'In which town is KQRX licensed?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2hop__837090_278127</td>\n",
       "      <td>[{'idx': 0, 'title': 'The Opening (album)', 'p...</td>\n",
       "      <td>Roc-A-Fella Records</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>The Opening is a live album by American jazz p...</td>\n",
       "      <td>What is the record label of the Do It Again pe...</td>\n",
       "      <td>[{'question': 'Who is the performer of the son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2hop__128895_11424</td>\n",
       "      <td>[{'idx': 0, 'title': 'Ehrhardt, South Carolina...</td>\n",
       "      <td>15,504</td>\n",
       "      <td>[]</td>\n",
       "      <td>True</td>\n",
       "      <td>Ehrhardt is a town in Bamberg County, South Ca...</td>\n",
       "      <td>How many households were there in the town WPU...</td>\n",
       "      <td>[{'question': 'In which town is WPUR licensed?...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         paragraphs  \\\n",
       "0  2hop__128801_205185  [{'idx': 0, 'title': 'Pama, Burkina Faso', 'pa...   \n",
       "1  2hop__719559_217649  [{'idx': 0, 'title': 'Antoine Marchand', 'para...   \n",
       "2  2hop__128806_205185  [{'idx': 0, 'title': 'Spanish Town', 'paragrap...   \n",
       "3  2hop__837090_278127  [{'idx': 0, 'title': 'The Opening (album)', 'p...   \n",
       "4   2hop__128895_11424  [{'idx': 0, 'title': 'Ehrhardt, South Carolina...   \n",
       "\n",
       "                answer           answer_aliases  answerable  \\\n",
       "0       Midland County  [Midland County, Texas]        True   \n",
       "1         Warner Bros.                       []        True   \n",
       "2       Midland County  [Midland County, Texas]        True   \n",
       "3  Roc-A-Fella Records                       []        True   \n",
       "4               15,504                       []        True   \n",
       "\n",
       "                                                text  \\\n",
       "0  Pama is a town located in the province of Komp...   \n",
       "1  Antoine Marchand is a record label established...   \n",
       "2  Spanish Town is the capital and the largest to...   \n",
       "3  The Opening is a live album by American jazz p...   \n",
       "4  Ehrhardt is a town in Bamberg County, South Ca...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What county is the town where KNFM is licensed...   \n",
       "1  What's the record label of the artist who put ...   \n",
       "2  What region is the town where KQRX is liscense...   \n",
       "3  What is the record label of the Do It Again pe...   \n",
       "4  How many households were there in the town WPU...   \n",
       "\n",
       "                              question_decomposition  \n",
       "0  [{'question': 'In which town is KNFM licensed?...  \n",
       "1  [{'question': 'Who is the artist who released ...  \n",
       "2  [{'question': 'In which town is KQRX licensed?...  \n",
       "3  [{'question': 'Who is the performer of the son...  \n",
       "4  [{'question': 'In which town is WPUR licensed?...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_df = pd.read_json('/Users/bdsaglam/knowledge/bellek/data/generated/musique-kg-llm/train/dataset.jsonl', orient='records', lines=True)\n",
    "qd_df = pd.read_json('/Users/bdsaglam/knowledge/bellek/data/generated/musique-kg-llm/train/question-decomposition.jsonl', orient='records', lines=True)\n",
    "df = pd.merge(ds_df.drop(columns=['question', 'question_decomposition']), qd_df, on='id', suffixes=('', ''))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_docs(example, only_supporting=False):\n",
    "    ps = example[\"paragraphs\"]\n",
    "    for p in ps:\n",
    "        if only_supporting and not p[\"is_supporting\"]:\n",
    "            continue\n",
    "        idx = p[\"idx\"]\n",
    "        title = p[\"title\"]\n",
    "        body = p[\"paragraph_text\"]\n",
    "        is_supporting = p[\"is_supporting\"]\n",
    "        text = f\"# {title}\\n{body}\"\n",
    "        yield Document(\n",
    "            text=text,\n",
    "            metadata={\"parent_id\": example[\"id\"], \"idx\": idx, \"is_supporting\": is_supporting},\n",
    "            excluded_llm_metadata_keys=[\"parent_id\", \"idx\", \"is_supporting\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weaviate_client = weaviate.Client(\"http://localhost:50080\")\n",
    "vector_store = WeaviateVectorStore(weaviate_client=weaviate_client)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "def make_query_engine(example):\n",
    "    documents = list(make_docs(example, only_supporting=False))\n",
    "    vector_index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        service_context=service_context,\n",
    "        vector_store_query_mode=\"hybrid\",\n",
    "        alpha=0.6,\n",
    "        similarity_top_k=3,\n",
    "    )\n",
    "    return query_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_answer_sub_question(example):\n",
    "    def answer_sub_question(question: str) -> str:\n",
    "        \"\"\"Use this tool to answer a sub-question.\"\"\"\n",
    "        return make_query_engine(example).query(question).response\n",
    "    return FunctionTool.from_defaults(fn=answer_sub_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_persist_tool():\n",
    "    outputs = []\n",
    "    def persist_answers(sub_answers: list[str], final_answer: str) -> str:\n",
    "        \"\"\"Save the sub-answers and final answer to a database at the end.\"\"\"\n",
    "        outputs.append(dict(final_answer=final_answer, sub_answers=sub_answers))\n",
    "        return \"SUCCESS\"\n",
    "\n",
    "    tool =  FunctionTool.from_defaults(fn=persist_answers)\n",
    "    def _get_output():\n",
    "        if outputs:\n",
    "            return outputs[-1]\n",
    "        else:\n",
    "            return None\n",
    "    tool._get_output = _get_output\n",
    "    return tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_STR = \"\"\"\n",
    "You are helpful multi-hop question answering assistant that answers the given question by answering each sub-question. You must use `answer_sub_question` tool to answer each sub-question. After you get the answer for the first question, you reformulate the second sub-question and repeat the same procedure. \n",
    "Your answers must be in 2-4 words. When you reach the final answer, you persist your answers to a database by calling `persist_answers` function only once. After that, you output \"FINISH\".\n",
    "\"\"\".strip()\n",
    "\n",
    "def make_mhqa_agent(example):\n",
    "    tools = [\n",
    "        make_answer_sub_question(example),\n",
    "        make_persist_tool(),\n",
    "    ]\n",
    "    prefix_messages = [\n",
    "        ChatMessage(content=SYSTEM_PROMPT_STR, role=\"system\"),\n",
    "    ]\n",
    "    return OpenAIAgent.from_tools(\n",
    "        tools, \n",
    "        prefix_messages=prefix_messages,\n",
    "        # verbose=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_question(example):\n",
    "    sub_questions = '\\n'.join([f\"\\t{i+1}.{item['question']}\" for i, item in enumerate(example['question_decomposition'])])\n",
    "    return f\"{example['question']}\\n\\n{sub_questions}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mhqa(example):\n",
    "    \"\"\"Multi-hop question answering.\"\"\"\n",
    "    agent = make_mhqa_agent(example)\n",
    "    response = agent.query(format_question(example)).response\n",
    "    output = agent.agent_worker._get_tools(None)[1]._get_output()\n",
    "    if output is None:\n",
    "        example['predicted_answer'] = None\n",
    "        example['predicted_sub_answers'] = None\n",
    "    else:\n",
    "        example['predicted_answer'] = output.get(\"final_answer\")\n",
    "        example['predicted_sub_answers'] = output.get('sub_answers')\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_correct(example):\n",
    "    pred, ref = example['predicted_answer'], example['answer']\n",
    "    return pred is not None and ((pred in ref) or fuzzy_match(pred, ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# example = df.iloc[i]\n",
    "# example_ = mhqa(example)\n",
    "# print(\"Reference answer:\", example['answer'])\n",
    "# print(\"Predictions:\")\n",
    "# print(example_['predicted_answer'])\n",
    "# print(example_['predicted_sub_answers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "I'm sorry, but there is no information available about the city where Robinella was formed.\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n",
      "FINISH\n"
     ]
    }
   ],
   "source": [
    "df = df.apply(mhqa, axis=1)\n",
    "df.to_json('/Users/bdsaglam/knowledge/bellek/data/generated/musique-kg-llm/train/baseline-agent.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.54"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_correct'] = df.apply(is_correct, axis=1)\n",
    "df['is_correct'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted_answer</th>\n",
       "      <th>predicted_sub_answers</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2hop__128801_205185</td>\n",
       "      <td>What county is the town where KNFM is licensed...</td>\n",
       "      <td>Midland County</td>\n",
       "      <td></td>\n",
       "      <td>[Senmonorom, ]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2hop__719559_217649</td>\n",
       "      <td>What's the record label of the artist who put ...</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>Columbia Records</td>\n",
       "      <td>[Paul Simon, Columbia Records]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2hop__128806_205185</td>\n",
       "      <td>What region is the town where KQRX is liscense...</td>\n",
       "      <td>Midland County</td>\n",
       "      <td></td>\n",
       "      <td>[Midland, Texas]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2hop__837090_278127</td>\n",
       "      <td>What is the record label of the Do It Again pe...</td>\n",
       "      <td>Roc-A-Fella Records</td>\n",
       "      <td>Roc-A-Fella Records</td>\n",
       "      <td>[Jay-Z, Roc-A-Fella Records]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2hop__128895_11424</td>\n",
       "      <td>How many households were there in the town WPU...</td>\n",
       "      <td>15,504</td>\n",
       "      <td>15,504</td>\n",
       "      <td>[Atlantic City, New Jersey, 15,504]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                           question  \\\n",
       "0  2hop__128801_205185  What county is the town where KNFM is licensed...   \n",
       "1  2hop__719559_217649  What's the record label of the artist who put ...   \n",
       "2  2hop__128806_205185  What region is the town where KQRX is liscense...   \n",
       "3  2hop__837090_278127  What is the record label of the Do It Again pe...   \n",
       "4   2hop__128895_11424  How many households were there in the town WPU...   \n",
       "\n",
       "                answer     predicted_answer  \\\n",
       "0       Midland County                        \n",
       "1         Warner Bros.     Columbia Records   \n",
       "2       Midland County                        \n",
       "3  Roc-A-Fella Records  Roc-A-Fella Records   \n",
       "4               15,504               15,504   \n",
       "\n",
       "                 predicted_sub_answers  is_correct  \n",
       "0                       [Senmonorom, ]        True  \n",
       "1       [Paul Simon, Columbia Records]       False  \n",
       "2                     [Midland, Texas]        True  \n",
       "3         [Jay-Z, Roc-A-Fella Records]        True  \n",
       "4  [Atlantic City, New Jersey, 15,504]        True  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['id', 'question', 'answer', 'predicted_answer', 'predicted_sub_answers', 'is_correct']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
