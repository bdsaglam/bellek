{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from functools import partial\n",
    "import magentic\n",
    "\n",
    "from bellek.qa.ablation import answer_question_standard, answer_question_cot, answer_question_cot_fs, answer_question_cte, answer_question_cte_cot\n",
    "from bellek.utils import set_seed, jprint\n",
    "from bellek.musique.singlehop import benchmark\n",
    "\n",
    "set_seed(89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.3f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RUNS = 1\n",
    "SAMPLE_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_aliases</th>\n",
       "      <th>answerable</th>\n",
       "      <th>answers</th>\n",
       "      <th>question</th>\n",
       "      <th>question_decomposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2hop__575188_342798</td>\n",
       "      <td>[{'idx': 0, 'title': 'Liliana Mumy', 'paragrap...</td>\n",
       "      <td>Ahmad Shah Qajar</td>\n",
       "      <td>[Ahmad Shah Qajar]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Ahmad Shah Qajar]</td>\n",
       "      <td>Who is the child of Mahmoud Mirza's father?</td>\n",
       "      <td>[{'id': 575188, 'question': 'Who is Mahmoud Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2hop__731584_700117</td>\n",
       "      <td>[{'idx': 0, 'title': 'KAPE', 'paragraph_text':...</td>\n",
       "      <td>Berrien County</td>\n",
       "      <td>[Berrien County]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Berrien County]</td>\n",
       "      <td>In which county is the city to which KKVU is l...</td>\n",
       "      <td>[{'id': 731584, 'question': 'To which city is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2hop__690412_526810</td>\n",
       "      <td>[{'idx': 0, 'title': 'Cabramatta Creek', 'para...</td>\n",
       "      <td>Chao Phraya River</td>\n",
       "      <td>[Chao Phraya River]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Chao Phraya River]</td>\n",
       "      <td>For what river does the river on which Pa Sak ...</td>\n",
       "      <td>[{'id': 690412, 'question': 'On which river is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2hop__263638_69048</td>\n",
       "      <td>[{'idx': 0, 'title': 'Michael J. Barron', 'par...</td>\n",
       "      <td>Honorable Justice Abiodun Smith</td>\n",
       "      <td>[Honorable Justice Abiodun Smith]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Honorable Justice Abiodun Smith]</td>\n",
       "      <td>Who is the Chief Judge of the Tebesa Nemine's ...</td>\n",
       "      <td>[{'id': 263638, 'question': 'Where was Tebesa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2hop__142842_68489</td>\n",
       "      <td>[{'idx': 0, 'title': 'Perfect Night: Live in L...</td>\n",
       "      <td>Snapper Foster</td>\n",
       "      <td>[Snapper Foster]</td>\n",
       "      <td>True</td>\n",
       "      <td>[Snapper Foster]</td>\n",
       "      <td>Who did the performer of Night Rocker play on ...</td>\n",
       "      <td>[{'id': 142842, 'question': 'Who performed Nig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                         paragraphs  \\\n",
       "0  2hop__575188_342798  [{'idx': 0, 'title': 'Liliana Mumy', 'paragrap...   \n",
       "1  2hop__731584_700117  [{'idx': 0, 'title': 'KAPE', 'paragraph_text':...   \n",
       "2  2hop__690412_526810  [{'idx': 0, 'title': 'Cabramatta Creek', 'para...   \n",
       "3   2hop__263638_69048  [{'idx': 0, 'title': 'Michael J. Barron', 'par...   \n",
       "4   2hop__142842_68489  [{'idx': 0, 'title': 'Perfect Night: Live in L...   \n",
       "\n",
       "                            answer                     answer_aliases  \\\n",
       "0                 Ahmad Shah Qajar                 [Ahmad Shah Qajar]   \n",
       "1                   Berrien County                   [Berrien County]   \n",
       "2                Chao Phraya River                [Chao Phraya River]   \n",
       "3  Honorable Justice Abiodun Smith  [Honorable Justice Abiodun Smith]   \n",
       "4                   Snapper Foster                   [Snapper Foster]   \n",
       "\n",
       "   answerable                            answers  \\\n",
       "0        True                 [Ahmad Shah Qajar]   \n",
       "1        True                   [Berrien County]   \n",
       "2        True                [Chao Phraya River]   \n",
       "3        True  [Honorable Justice Abiodun Smith]   \n",
       "4        True                   [Snapper Foster]   \n",
       "\n",
       "                                            question  \\\n",
       "0        Who is the child of Mahmoud Mirza's father?   \n",
       "1  In which county is the city to which KKVU is l...   \n",
       "2  For what river does the river on which Pa Sak ...   \n",
       "3  Who is the Chief Judge of the Tebesa Nemine's ...   \n",
       "4  Who did the performer of Night Rocker play on ...   \n",
       "\n",
       "                              question_decomposition  \n",
       "0  [{'id': 575188, 'question': 'Who is Mahmoud Mi...  \n",
       "1  [{'id': 731584, 'question': 'To which city is ...  \n",
       "2  [{'id': 690412, 'question': 'On which river is...  \n",
       "3  [{'id': 263638, 'question': 'Where was Tebesa ...  \n",
       "4  [{'id': 142842, 'question': 'Who performed Nig...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bellek.musique.constants import ABLATION_RECORD_IDS\n",
    "\n",
    "df = pd.read_json('../../data/generated/musique-evaluation/dataset.jsonl', orient='records', lines=True)\n",
    "df = df.set_index('id', drop=False).loc[ABLATION_RECORD_IDS].copy().reset_index(drop=True)\n",
    "qd_df = pd.read_json('../../data/generated/musique-evaluation/question-decomposition.jsonl', orient='records', lines=True)\n",
    "df = pd.merge(df.drop(columns=['question', 'question_decomposition']), qd_df, on='id', suffixes=('', ''))\n",
    "df = df.head(SAMPLE_SIZE)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_retrieval_func = lambda docs, query: [doc for doc in docs if doc['is_supporting']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d10b0627ed2419f97cc66a2f7430aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.58,\n",
      "  \"f1\": 0.674219421101774,\n",
      "  \"fuzzy_match\": 0.71\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbb66e5b76d4b34b4db02edf38787f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.59,\n",
      "  \"f1\": 0.7086811815635343,\n",
      "  \"fuzzy_match\": 0.73\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a9b57994804fc186a3e1ba6ec178e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.58,\n",
      "  \"f1\": 0.6840289449112977,\n",
      "  \"fuzzy_match\": 0.73\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d65290837d4f94b43d2f60aa2b686a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.62,\n",
      "  \"f1\": 0.7233478482302012,\n",
      "  \"fuzzy_match\": 0.76\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee1877ccd9c14294ac6f5f7bba52e06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.56,\n",
      "  \"f1\": 0.6769910938734466,\n",
      "  \"fuzzy_match\": 0.71\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80573b87a721499e8bd1aac96490b4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.63,\n",
      "  \"f1\": 0.7329337068160596,\n",
      "  \"fuzzy_match\": 0.75\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065b52d92283408a9350c233e817c272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.54,\n",
      "  \"f1\": 0.6589593478417008,\n",
      "  \"fuzzy_match\": 0.7\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32565ce30e2a4bbfafe57fe35533f99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.59,\n",
      "  \"f1\": 0.7163625730994151,\n",
      "  \"fuzzy_match\": 0.75\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd941089b6f4cdc9f84d207d228440a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.53,\n",
      "  \"f1\": 0.6506003734827265,\n",
      "  \"fuzzy_match\": 0.69\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467209b9700e4f6aa5cb7534c1f8c713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.62,\n",
      "  \"f1\": 0.7178716577540107,\n",
      "  \"fuzzy_match\": 0.74\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6aaffe7aad4266aac2990d2d4011db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.58,\n",
      "  \"f1\": 0.6700765639589167,\n",
      "  \"fuzzy_match\": 0.71\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37deb3b5d87944b6a8303ced2beeeafc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.61,\n",
      "  \"f1\": 0.7176811815635346,\n",
      "  \"fuzzy_match\": 0.74\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c91fba591947f48a9c25771c730ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.53,\n",
      "  \"f1\": 0.6512796092796093,\n",
      "  \"fuzzy_match\": 0.66\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b2da989df04f839017126325079fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"exact_match\": 0.56,\n",
      "  \"f1\": 0.6821718020541551,\n",
      "  \"fuzzy_match\": 0.68\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274a95f0da4a4d0893beb84364daed03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to answer the question 2hop__575188_342798\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__95970_456836\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__280451_84616\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__543853_124498\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__785711_63853\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__126306_396277\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__424908_500483\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__433694_20273\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "{\n",
      "  \"exact_match\": 0.4,\n",
      "  \"f1\": 0.5006299811299811,\n",
      "  \"fuzzy_match\": 0.49\n",
      "}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b15ef29bd13498cb270c409ff31da4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to answer the question 2hop__142842_68489\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__189094_612080\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__819974_129669\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__852657_155922\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__128420_375952\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__144303_483189\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__862994_69048\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__271045_68633\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__582045_161450\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__310456_846599\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__776377_857193\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__12039_11957\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__785711_73244\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__75169_92673\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__427249_20057\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__466700_214359\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__477492_240386\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__333020_69048\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__280451_84616\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__620853_22458\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__226204_69048\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__543853_124498\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__142443_768138\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__559273_152023\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__223655_463572\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__507722_124896\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__153532_45326\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__128342_375952\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__539184_119915\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__199513_801817\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__797443_120537\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__92385_2072\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__418941_429437\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__152229_604644\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__693444_220151\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__131951_643670\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__850984_7292\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__518354_67465\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__136067_160249\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__424908_500483\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "Failed to answer the question 2hop__130867_54221\n",
      "Failed to parse model output. You may need to update your prompt to encourage the model to return a specific type.\n",
      "{\n",
      "  \"exact_match\": 0.23,\n",
      "  \"f1\": 0.30778654678654677,\n",
      "  \"fuzzy_match\": 0.32\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for temperature in [0.0, 0.1, 0.3, 0.5, 0.7, 1.0, 1.5, 2.0]:\n",
    "    with magentic.OpenaiChatModel(\"gpt-3.5-turbo\", temperature=temperature):\n",
    "        for qa_prompting, qa_func in [('standard', answer_question_standard), ('cte', answer_question_cte)]:\n",
    "            for i in range(1, N_RUNS+1):\n",
    "                _, scores = benchmark(df, qa_func, perfect_retrieval_func, ignore_errors=True)\n",
    "                results.append({**scores, \"retrieval\": \"groundtruth\", \"context\": \"paragraphs\", \"qa\": qa_prompting, \"temperature\": temperature, \"run\": i})\n",
    "                jprint(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>retrieval</th>\n",
       "      <th>qa</th>\n",
       "      <th>temperature</th>\n",
       "      <th>run</th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>standard</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>cte</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>standard</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>cte</td>\n",
       "      <td>0.100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>standard</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>cte</td>\n",
       "      <td>0.300</td>\n",
       "      <td>1</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>standard</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.540</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>cte</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>standard</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>cte</td>\n",
       "      <td>0.700</td>\n",
       "      <td>1</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>standard</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>cte</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>standard</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>cte</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>standard</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400</td>\n",
       "      <td>0.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>paragraphs</td>\n",
       "      <td>groundtruth</td>\n",
       "      <td>cte</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       context    retrieval        qa  temperature  run  exact_match    f1\n",
       "0   paragraphs  groundtruth  standard        0.000    1        0.580 0.674\n",
       "1   paragraphs  groundtruth       cte        0.000    1        0.590 0.709\n",
       "2   paragraphs  groundtruth  standard        0.100    1        0.580 0.684\n",
       "3   paragraphs  groundtruth       cte        0.100    1        0.620 0.723\n",
       "4   paragraphs  groundtruth  standard        0.300    1        0.560 0.677\n",
       "5   paragraphs  groundtruth       cte        0.300    1        0.630 0.733\n",
       "6   paragraphs  groundtruth  standard        0.500    1        0.540 0.659\n",
       "7   paragraphs  groundtruth       cte        0.500    1        0.590 0.716\n",
       "8   paragraphs  groundtruth  standard        0.700    1        0.530 0.651\n",
       "9   paragraphs  groundtruth       cte        0.700    1        0.620 0.718\n",
       "10  paragraphs  groundtruth  standard        1.000    1        0.580 0.670\n",
       "11  paragraphs  groundtruth       cte        1.000    1        0.610 0.718\n",
       "12  paragraphs  groundtruth  standard        1.500    1        0.530 0.651\n",
       "13  paragraphs  groundtruth       cte        1.500    1        0.560 0.682\n",
       "14  paragraphs  groundtruth  standard        2.000    1        0.400 0.501\n",
       "15  paragraphs  groundtruth       cte        2.000    1        0.230 0.308"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df = pd.DataFrame.from_records(results, columns=['context', 'retrieval', 'qa', 'temperature', 'run', 'exact_match', 'f1'])\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "suffix = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "report_df.to_json(f'./ablation-temperature-{suffix}.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>exact_match</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa</th>\n",
       "      <th>temperature</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">cte</th>\n",
       "      <th>0.000</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.300</th>\n",
       "      <td>0.630</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.590</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.700</th>\n",
       "      <td>0.620</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0.718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.500</th>\n",
       "      <td>0.560</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.000</th>\n",
       "      <td>0.230</td>\n",
       "      <td>0.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">standard</th>\n",
       "      <th>0.000</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.100</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.300</th>\n",
       "      <td>0.560</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.500</th>\n",
       "      <td>0.540</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.700</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000</th>\n",
       "      <td>0.580</td>\n",
       "      <td>0.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.500</th>\n",
       "      <td>0.530</td>\n",
       "      <td>0.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.000</th>\n",
       "      <td>0.400</td>\n",
       "      <td>0.501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      exact_match    f1\n",
       "qa       temperature                   \n",
       "cte      0.000              0.590 0.709\n",
       "         0.100              0.620 0.723\n",
       "         0.300              0.630 0.733\n",
       "         0.500              0.590 0.716\n",
       "         0.700              0.620 0.718\n",
       "         1.000              0.610 0.718\n",
       "         1.500              0.560 0.682\n",
       "         2.000              0.230 0.308\n",
       "standard 0.000              0.580 0.674\n",
       "         0.100              0.580 0.684\n",
       "         0.300              0.560 0.677\n",
       "         0.500              0.540 0.659\n",
       "         0.700              0.530 0.651\n",
       "         1.000              0.580 0.670\n",
       "         1.500              0.530 0.651\n",
       "         2.000              0.400 0.501"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df.drop(columns=['context', 'retrieval', 'run']).groupby(['qa', 'temperature']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrr}\n",
      "\\toprule\n",
      " &  & exact_match & f1 \\\\\n",
      "qa & temperature &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{8}{*}{cte} & 0.000000 & 0.590000 & 0.708681 \\\\\n",
      " & 0.100000 & 0.620000 & 0.723348 \\\\\n",
      " & 0.300000 & 0.630000 & 0.732934 \\\\\n",
      " & 0.500000 & 0.590000 & 0.716363 \\\\\n",
      " & 0.700000 & 0.620000 & 0.717872 \\\\\n",
      " & 1.000000 & 0.610000 & 0.717681 \\\\\n",
      " & 1.500000 & 0.560000 & 0.682172 \\\\\n",
      " & 2.000000 & 0.230000 & 0.307787 \\\\\n",
      "\\cline{1-4}\n",
      "\\multirow[t]{8}{*}{standard} & 0.000000 & 0.580000 & 0.674219 \\\\\n",
      " & 0.100000 & 0.580000 & 0.684029 \\\\\n",
      " & 0.300000 & 0.560000 & 0.676991 \\\\\n",
      " & 0.500000 & 0.540000 & 0.658959 \\\\\n",
      " & 0.700000 & 0.530000 & 0.650600 \\\\\n",
      " & 1.000000 & 0.580000 & 0.670077 \\\\\n",
      " & 1.500000 & 0.530000 & 0.651280 \\\\\n",
      " & 2.000000 & 0.400000 & 0.500630 \\\\\n",
      "\\cline{1-4}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report_df.drop(columns=['context', 'retrieval', 'run']).groupby(['qa', 'temperature']).mean().to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
