{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph Construction\n",
    "> Relation and entity extraction from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp ml.kg.cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import TypeAlias, Iterable, Callable, Any, Generator\n",
    "import numpy as np\n",
    "\n",
    "from bellek.logging import get_logger\n",
    "\n",
    "log = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import json\n",
    "def pprint(obj):\n",
    "    print(json.dumps(obj, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "Entity: TypeAlias = str|tuple[str, str]\n",
    "Relation: TypeAlias = str\n",
    "Triplet: TypeAlias = tuple[Entity, Relation, Entity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def evaluate_joint_er_extraction(*, reference: Iterable[Triplet], prediction: Iterable[Triplet]):\n",
    "    \"\"\"\n",
    "    Example: [(('John', 'PERSON'), 'works_at', ('Google', 'ORG'))]\n",
    "    \"\"\"\n",
    "\n",
    "    reference_set = set(reference)\n",
    "    prediction_set = set(prediction)\n",
    "    assert len(reference) == len(reference_set), \"Duplicates found in references\"\n",
    "\n",
    "    TP = len(reference_set & prediction_set)\n",
    "    FP = len(prediction_set - reference_set)\n",
    "    FN = len(reference_set - prediction_set)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1_score\n",
    "    }\n",
    "\n",
    "def evaluate_joint_er_extractions(*, references: Iterable[Iterable[Triplet]], predictions: Iterable[Iterable[Triplet]]):\n",
    "    score_dicts = [\n",
    "        evaluate_joint_er_extraction(reference=reference, prediction=prediction) \n",
    "        for reference, prediction in zip(references, predictions)\n",
    "    ]\n",
    "    return {('mean_' + key): np.mean([scores[key] for scores in score_dicts]) for key in score_dicts[0].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4}\n"
     ]
    }
   ],
   "source": [
    "reference = [(('John', 'PERSON'), 'works_at', ('Google', 'ORG')), (('Mike', 'PERSON'), 'lives_in', ('Paris', 'LOC')), (('Dwight', 'PERSON'), 'sells', ('Paper', 'OBJ'))]\n",
    "prediction = [(('John', 'PERSON'), 'works_at', ('Google', 'ORG')), (('Mike', 'PERSON'), 'lives_in', ('New York', 'LOC'))]\n",
    "\n",
    "scores = evaluate_joint_er_extraction(reference=reference, prediction=prediction)\n",
    "test_eq(scores, {'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4})\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_precision': 0.25, 'mean_recall': 0.16666666666666666, 'mean_f1': 0.2}\n"
     ]
    }
   ],
   "source": [
    "references = [\n",
    "    [(('John', 'PERSON'), 'works_at', ('Google', 'ORG')), (('Mike', 'PERSON'), 'lives_in', ('Paris', 'LOC')), (('Dwight', 'PERSON'), 'sells', ('Paper', 'OBJ'))],\n",
    "    [(('Henry', 'PERSON'), 'founded', ('Ford', 'ORG'))],\n",
    "]\n",
    "predictions = [\n",
    "    [(('John', 'PERSON'), 'works_at', ('Google', 'ORG')), (('Mike', 'PERSON'), 'lives_in', ('New York', 'LOC'))],\n",
    "    [(('Henry', 'PERSON'), 'founded', ('Boston Dynamics', 'ORG'))],\n",
    "]\n",
    "\n",
    "scores = evaluate_joint_er_extractions(references=references, predictions=predictions)\n",
    "test_eq(scores, {'mean_precision': 0.25, 'mean_recall': 0.16666666666666666, 'mean_f1': 0.2})\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def parse_triplet_strings(text: str, delimiter: str=\"|\") -> list[str]:\n",
    "    return [line for line in text.splitlines() if line and line.count(delimiter) == 2]\n",
    "\n",
    "def parse_triplets(text: str, delimiter: str=\"|\") -> list[Triplet]:\n",
    "    return [tuple(triplet_string.split(delimiter)) for triplet_string in parse_triplet_strings(text, delimiter=delimiter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "text = \"\"\"\n",
    "  Sure! Here are the entity-relation-entity triplets for the given text:\n",
    "\n",
    "Aleksandre_Guruli|club|US_Lesquin\n",
    "Paris|capitalOf|France\n",
    "\n",
    "Please provide the next text for extraction.\n",
    "\"\"\"\n",
    "assert sorted(parse_triplet_strings(text)) == [\"Aleksandre_Guruli|club|US_Lesquin\", \"Paris|capitalOf|France\"]\n",
    "assert sorted(parse_triplets(text)) == [(\"Aleksandre_Guruli\", \"club\", \"US_Lesquin\"), ('Paris', 'capitalOf', 'France')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting for joint entity-relation extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def format_triplets(triplets: Iterable[str]) -> str:\n",
    "    return '\\n'.join(triplets)\n",
    "\n",
    "def format_few_shot_example(example, text_prefix=\"# Text\\n\", triplets_prefix=\"# Triplets\\n\"):\n",
    "    text = example['text']\n",
    "    triplets = format_triplets(example['triplets'])\n",
    "    return f\"{text_prefix}{text}\\n{triplets_prefix}{triplets}\"\n",
    "\n",
    "def format_few_shot_examples(examples):\n",
    "    return \"\\n\\n\".join([format_few_shot_example(example) for example in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT_TEMPLATE = \"\"\"You are a helpful assistant that extracts entity-relation-entity triplets from given text.\n",
    "{relation_set_prompt}\n",
    "{few_shot_prompt}\n",
    "\"\"\".strip()\n",
    "\n",
    "DEFAULT_RELATION_SET_PROMPT_TEMPLATE = \"\"\"Here are the list of relations that you can use:\n",
    "{relation_set}\n",
    "\"\"\"\n",
    "\n",
    "DEFAULT_FEW_SHOT_EXAMPLES_PROMPT_TEMPLATE = \"\"\"Use the same format for triplets as in the examples provided below.\n",
    "{few_shot_examples}\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class ERX2AlpacaFormatter:\n",
    "    system_prompt_template: str = DEFAULT_SYSTEM_PROMPT_TEMPLATE\n",
    "    relation_set_prompt_template: str = DEFAULT_RELATION_SET_PROMPT_TEMPLATE\n",
    "    relation_set: set|None = None\n",
    "    few_shot_examples_prompt_template: str = DEFAULT_FEW_SHOT_EXAMPLES_PROMPT_TEMPLATE\n",
    "    few_shot_examples: list[dict]|None = None\n",
    "    n_few_shot_examples: int = 3\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.relation_set:\n",
    "            self.relation_set = sorted(self.relation_set)\n",
    "        if self.few_shot_examples is not None:\n",
    "            self.few_shot_examples = list(self.few_shot_examples)\n",
    "\n",
    "    def format(self, example: dict):\n",
    "        instruction = self.make_system_prompt()\n",
    "        input = example['text']\n",
    "        output = '\\n'.join(example['triplets'])\n",
    "        return {\n",
    "            'instruction': instruction.strip(),\n",
    "            'input': input.strip(),\n",
    "            'output': output.strip(),\n",
    "        }\n",
    "\n",
    "    def make_system_prompt(self) -> str:\n",
    "        rsp = self.relation_set_prompt_template.format(relation_set=','.join(self.relation_set)) if self.relation_set else \"\"\n",
    "        fsp = self.few_shot_examples_prompt_template.format(few_shot_examples=format_few_shot_examples(self._choose_few_shot_examples())) if self.few_shot_examples else \"\"\n",
    "        return self.system_prompt_template.format(relation_set_prompt=rsp, few_shot_prompt=fsp)\n",
    "\n",
    "    def _choose_few_shot_examples(self) -> list[dict]:\n",
    "        if len(self.few_shot_examples) <= self.n_few_shot_examples:\n",
    "            return self.few_shot_examples\n",
    "        else:\n",
    "            return random.sample(self.few_shot_examples, k=self.n_few_shot_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'You are a helpful assistant that extracts entity-relation-entity triplets from given text.',\n",
       " 'input': \"Dead Man's Plack is found in England and is made from rock. The capital of England is London and its religion is Church of England. The British Arabs are an English ethnic group.\",\n",
       " 'output': \"Dead_Man's_Plack|location|England\\nEngland|ethnicGroup|British_Arabs\"}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = {\n",
    "    \"text\": \"Dead Man's Plack is found in England and is made from rock. The capital of England is London and its religion is Church of England. The British Arabs are an English ethnic group.\",\n",
    "    \"triplets\": [\n",
    "        \"Dead_Man's_Plack|location|England\",\n",
    "        \"England|ethnicGroup|British_Arabs\",\n",
    "    ],\n",
    "}\n",
    "erx2alpaca_formatter = ERX2AlpacaFormatter()\n",
    "alpaca_example = erx2alpaca_formatter.format(example)\n",
    "assert \"instruction\" in alpaca_example and \"input\" in alpaca_example and \"output\" in alpaca_example\n",
    "alpaca_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "{'instruction': 'You are a helpful assistant that extracts entity-relation-entity triplets from given text.\\n\\nUse the same format for triplets as in the examples provided below.\\n# Text\\nLondon is capital city of UK\\n# Triplets\\nLondon|capital of|UK', 'input': 'Moscow is capital city of Russia', 'output': 'Moscow|capital of|Russia'}\n",
      "================================================================================\n",
      "{'instruction': 'You are a helpful assistant that extracts entity-relation-entity triplets from given text.\\n\\nUse the same format for triplets as in the examples provided below.\\n# Text\\nParis is capital city of France\\n# Triplets\\nParis|capital of|France', 'input': 'Moscow is capital city of Russia', 'output': 'Moscow|capital of|Russia'}\n",
      "================================================================================\n",
      "{'instruction': 'You are a helpful assistant that extracts entity-relation-entity triplets from given text.\\n\\nUse the same format for triplets as in the examples provided below.\\n# Text\\nLondon is capital city of UK\\n# Triplets\\nLondon|capital of|UK', 'input': 'Moscow is capital city of Russia', 'output': 'Moscow|capital of|Russia'}\n"
     ]
    }
   ],
   "source": [
    "few_shot_examples = [\n",
    "    {\n",
    "        \"text\": \"Ankara is capital city of Turkey\",\n",
    "        \"triplets\": [\n",
    "            \"Ankara|capital of|Turkey\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Paris is capital city of France\",\n",
    "        \"triplets\": [\n",
    "            \"Paris|capital of|France\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"London is capital city of UK\",\n",
    "        \"triplets\": [\n",
    "            \"London|capital of|UK\",\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "example = {\n",
    "    \"text\": \"Moscow is capital city of Russia\",\n",
    "    \"triplets\": [\n",
    "        \"Moscow|capital of|Russia\",\n",
    "    ],\n",
    "}\n",
    "erx2alpaca_formatter = ERX2AlpacaFormatter(few_shot_examples=few_shot_examples, n_few_shot_examples=1)\n",
    "for i in range(3):\n",
    "    print(\"=\"*80)\n",
    "    print(erx2alpaca_formatter.format(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT_TEMPLATE2 = \"\"\"You are a helpful assistant that extracts entity-relation-entity triplets from given text. Use '|' as delimiter and provide one triplet per line.\n",
    "{relation_set_prompt}\n",
    "\"\"\".strip()\n",
    "\n",
    "DEFAULT_RELATION_SET_PROMPT_TEMPLATE2 = \"\"\"Here are the list of relations that you can use:\n",
    "{relation_set}\n",
    "\"\"\".strip()\n",
    "\n",
    "@dataclass\n",
    "class ERX2ChatFormatter:\n",
    "    system_prompt_template: str = DEFAULT_SYSTEM_PROMPT_TEMPLATE2\n",
    "    relation_set_prompt_template: str = DEFAULT_RELATION_SET_PROMPT_TEMPLATE2\n",
    "    relation_set: set|None = None\n",
    "    few_shot_examples: list[dict]|None = None\n",
    "    n_few_shot_examples: int = 3\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.relation_set:\n",
    "            self.relation_set = sorted(self.relation_set)\n",
    "        if self.few_shot_examples is not None:\n",
    "            self.few_shot_examples = list(self.few_shot_examples)\n",
    "\n",
    "    def format(self, example: dict):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.make_system_message()},\n",
    "            *list(self.make_messages(*self._choose_few_shot_examples(), example)),\n",
    "        ]\n",
    "        return {'conversations': messages}\n",
    "\n",
    "    def make_system_message(self) -> str:\n",
    "        rsp = self.relation_set_prompt_template.format(relation_set=','.join(self.relation_set)) if self.relation_set else \"\"\n",
    "        return self.system_prompt_template.format(relation_set_prompt=rsp)\n",
    "\n",
    "    def make_messages(self, *examples) -> Generator[dict, None, None]:\n",
    "        for example in examples:\n",
    "            yield {\"role\": \"user\", \"content\": example[\"text\"]}\n",
    "            yield {\"role\": \"assistant\", \"content\": format_triplets(example[\"triplets\"])}\n",
    "\n",
    "    def _choose_few_shot_examples(self) -> list[dict]:\n",
    "        if len(self.few_shot_examples) <= self.n_few_shot_examples:\n",
    "            return self.few_shot_examples\n",
    "        else:\n",
    "            return random.sample(self.few_shot_examples, k=self.n_few_shot_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "{\n",
      "  \"conversations\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful assistant that extracts entity-relation-entity triplets from given text. Use '|' as delimiter and provide one triplet per line.\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"London is capital city of UK\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"London|capital of|UK\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"Moscow is capital city of Russia\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Moscow|capital of|Russia\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "================================================================================\n",
      "{\n",
      "  \"conversations\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful assistant that extracts entity-relation-entity triplets from given text. Use '|' as delimiter and provide one triplet per line.\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"Paris is capital city of France\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Paris|capital of|France\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"Moscow is capital city of Russia\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Moscow|capital of|Russia\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "================================================================================\n",
      "{\n",
      "  \"conversations\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a helpful assistant that extracts entity-relation-entity triplets from given text. Use '|' as delimiter and provide one triplet per line.\\n\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"London is capital city of UK\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"London|capital of|UK\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"Moscow is capital city of Russia\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Moscow|capital of|Russia\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "few_shot_examples = [\n",
    "    {\n",
    "        \"text\": \"Ankara is capital city of Turkey\",\n",
    "        \"triplets\": [\n",
    "            \"Ankara|capital of|Turkey\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Paris is capital city of France\",\n",
    "        \"triplets\": [\n",
    "            \"Paris|capital of|France\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"London is capital city of UK\",\n",
    "        \"triplets\": [\n",
    "            \"London|capital of|UK\",\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "example = {\n",
    "    \"text\": \"Moscow is capital city of Russia\",\n",
    "    \"triplets\": [\n",
    "        \"Moscow|capital of|Russia\",\n",
    "    ],\n",
    "}\n",
    "erx2chat_formatter = ERX2ChatFormatter(few_shot_examples=few_shot_examples, n_few_shot_examples=1)\n",
    "for i in range(3):\n",
    "    print(\"=\"*80)\n",
    "    pprint(erx2chat_formatter.format(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of joint entity-relation extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "\n",
    "def evaluate_pipe_jer(dataset, pipe):\n",
    "    import evaluate\n",
    "\n",
    "    log.info(f\"Evaluating model for JER on dataset with {len(dataset)} samples.\")\n",
    "\n",
    "    results = pipe(dataset[\"input\"])\n",
    "    generations = [result[0][\"generated_text\"] for result in results]\n",
    "    predictions = [parse_triplet_strings(text.strip()) for text in generations]\n",
    "    references = [parse_triplet_strings(text.strip()) for text in dataset[\"output\"]]\n",
    "\n",
    "    dataf = dataset.to_pandas()\n",
    "    dataf[\"generation\"] = generations\n",
    "    dataf[\"prediction\"] = predictions\n",
    "    dataf[\"reference\"] = references\n",
    "\n",
    "    metric = evaluate.load(\"bdsaglam/jer\")\n",
    "    scores = metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "    return scores, dataf\n",
    "\n",
    "\n",
    "def evaluate_model_jer(\n",
    "    dataset,\n",
    "    *,\n",
    "    response_template: str,\n",
    "    tokenizer,\n",
    "    model,\n",
    "    max_new_tokens=256,\n",
    "    batch_size=4,\n",
    "    **kwargs,\n",
    "):\n",
    "    assert len(dataset) > 0, \"Dataset is empty!\"\n",
    "\n",
    "    def extract_input_output(example):\n",
    "        input, output = example[\"text\"].rsplit(response_template, 1)\n",
    "        input += response_template\n",
    "        output = output.replace(tokenizer.special_tokens_map[\"eos_token\"], \"\")\n",
    "        return {\"input\": input, \"output\": output}\n",
    "\n",
    "    dataset = dataset.map(extract_input_output)\n",
    "\n",
    "    # setup generation pipeline\n",
    "    from transformers import pipeline\n",
    "\n",
    "    pipe = pipeline(\n",
    "        task=\"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        batch_size=batch_size,\n",
    "        return_full_text=False,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    return evaluate_pipe_jer(dataset, pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
