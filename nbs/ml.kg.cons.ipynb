{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph Construction\n",
    "> Relation and entity extraction from text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ml.kg.cons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from dataclasses import dataclass\n",
    "from typing import TypeAlias, Iterable, List, Set, Tuple, Callable, Any, Dict\n",
    "import numpy as np\n",
    "from bellek.ml.llm.utils import LLAMA2_CHAT_PROMPT_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "Entity: TypeAlias = str | tuple[str, str]\n",
    "Relation: TypeAlias = str\n",
    "Triplet: TypeAlias = tuple[Entity, Relation, Entity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def evaluate_joint_er_extraction(*, reference: Iterable[Triplet], prediction: Iterable[Triplet]):\n",
    "    \"\"\"\n",
    "    Example: [(('John', 'PERSON'), 'works_at', ('Google', 'ORG'))]\n",
    "    \"\"\"\n",
    "\n",
    "    reference_set = set(reference)\n",
    "    prediction_set = set(prediction)\n",
    "    assert len(reference) == len(reference_set), \"Duplicates found in references\"\n",
    "\n",
    "    TP = len(reference_set & prediction_set)\n",
    "    FP = len(prediction_set - reference_set)\n",
    "    FN = len(reference_set - prediction_set)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "    recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1_score\n",
    "    }\n",
    "\n",
    "def evaluate_joint_er_extractions(*, references: Iterable[Iterable[Triplet]], predictions: Iterable[Iterable[Triplet]]):\n",
    "    score_dicts = [\n",
    "        evaluate_joint_er_extraction(reference=reference, prediction=prediction) \n",
    "        for reference, prediction in zip(references, predictions)\n",
    "    ]\n",
    "    return {('mean_' + key): np.mean([scores[key] for scores in score_dicts]) for key in score_dicts[0].keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4}\n"
     ]
    }
   ],
   "source": [
    "reference = [(('John', 'PERSON'), 'works_at', ('Google', 'ORG')), (('Mike', 'PERSON'), 'lives_in', ('Paris', 'LOC')), (('Dwight', 'PERSON'), 'sells', ('Paper', 'OBJ'))]\n",
    "prediction = [(('John', 'PERSON'), 'works_at', ('Google', 'ORG')), (('Mike', 'PERSON'), 'lives_in', ('New York', 'LOC'))]\n",
    "\n",
    "scores = evaluate_joint_er_extraction(reference=reference, prediction=prediction)\n",
    "test_eq(scores, {'precision': 0.5, 'recall': 0.3333333333333333, 'f1': 0.4})\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_precision': 0.25, 'mean_recall': 0.16666666666666666, 'mean_f1': 0.2}\n"
     ]
    }
   ],
   "source": [
    "references = [\n",
    "    [(('John', 'PERSON'), 'works_at', ('Google', 'ORG')), (('Mike', 'PERSON'), 'lives_in', ('Paris', 'LOC')), (('Dwight', 'PERSON'), 'sells', ('Paper', 'OBJ'))],\n",
    "    [(('Henry', 'PERSON'), 'founded', ('Ford', 'ORG'))],\n",
    "]\n",
    "predictions = [\n",
    "    [(('John', 'PERSON'), 'works_at', ('Google', 'ORG')), (('Mike', 'PERSON'), 'lives_in', ('New York', 'LOC'))],\n",
    "    [(('Henry', 'PERSON'), 'founded', ('Boston Dynamics', 'ORG'))],\n",
    "]\n",
    "\n",
    "scores = evaluate_joint_er_extractions(references=references, predictions=predictions)\n",
    "test_eq(scores, {'mean_precision': 0.25, 'mean_recall': 0.16666666666666666, 'mean_f1': 0.2})\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def parse_triplet_strings(text: str, delimiter: str=\" | \") -> List[str]:\n",
    "    return [line for line in text.splitlines() if line and line.count(delimiter) == 2]\n",
    "\n",
    "def parse_triplets(text: str, delimiter: str=\" | \") -> List[Triplet]:\n",
    "    return [tuple(triplet_string.split(delimiter)) for triplet_string in parse_triplet_strings(text, delimiter=delimiter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "text = \"\"\"\n",
    "  Sure! Here are the entity-relation-entity triplets for the given text:\n",
    "\n",
    "Aleksandre_Guruli | club | US_Lesquin\n",
    "Paris | capitalOf | France\n",
    "\n",
    "Please provide the next text for extraction.\n",
    "\"\"\"\n",
    "assert sorted(parse_triplet_strings(text)) == [\"Aleksandre_Guruli | club | US_Lesquin\", \"Paris | capitalOf | France\"]\n",
    "assert sorted(parse_triplets(text)) == [(\"Aleksandre_Guruli\", \"club\", \"US_Lesquin\"), ('Paris', 'capitalOf', 'France')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def format_few_shot_example(example, text_prefix=\"# Text\\n\", triplets_prefix=\"# Triplets\\n\"):\n",
    "    text = example['text']\n",
    "    triplets = '\\n'.join(example['triplets'])\n",
    "    return f\"{text_prefix}{text}\\n{triplets_prefix}{triplets}\"\n",
    "\n",
    "def format_few_shot_examples(examples):\n",
    "    return \"\\n\\n\".join([format_few_shot_example(example) for example in examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "DEFAULT_RELATION_SET_PROMPT_TEMPLATE = \"\"\"Here are the list of relations that you can use:\n",
    "{relation_set}\n",
    "\"\"\"\n",
    "\n",
    "DEFAULT_FEW_SHOT_EXAMPLES_PROMPT_TEMPLATE = \"\"\"Use the same format for triplets as in the examples provided below.\n",
    "{few_shot_examples}\n",
    "\"\"\"\n",
    "\n",
    "DEFAULT_SYSTEM_PROMPT_TEMPLATE = \"\"\"You are helpful assistant that extracts entity-relation-entity triplets from given text.\n",
    "{relation_set_prompt}\n",
    "{few_shot_prompt}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ERXFormatter:\n",
    "    chat_prompt_template: str = LLAMA2_CHAT_PROMPT_TEMPLATE\n",
    "    system_prompt_template: str = DEFAULT_SYSTEM_PROMPT_TEMPLATE\n",
    "    few_shot_examples_prompt_template: str = DEFAULT_FEW_SHOT_EXAMPLES_PROMPT_TEMPLATE\n",
    "    few_shot_examples: List[Dict] | None = None\n",
    "    n_few_shot_examples: int = 3\n",
    "    relation_set_prompt_template: str = DEFAULT_RELATION_SET_PROMPT_TEMPLATE\n",
    "    relation_set: set | None = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.relation_set:\n",
    "            self.relation_set = sorted(self.relation_set)\n",
    "\n",
    "    def format_for_inference(self, example: Dict):\n",
    "        example = {**example}\n",
    "        user_message = example['text']\n",
    "        example['text'] = self.chat_prompt_template.format(system_prompt=self.make_system_prompt(), user_message=user_message)\n",
    "        return example\n",
    "\n",
    "    def format_for_train(self, example: Dict):\n",
    "        example = {**example}\n",
    "        example['text'] = self.format_for_inference(example)['text'] + \" \" + '\\n'.join(example['triplets'])\n",
    "        return example\n",
    "\n",
    "    def make_system_prompt(self) -> str:\n",
    "        rsp = self.relation_set_prompt_template.format(relation_set=','.join(self.relation_set)) if self.relation_set else \"\"\n",
    "        fsp = self.few_shot_examples_prompt_template.format(few_shot_examples=format_few_shot_examples(self._choose_few_shot_examples())) if self.few_shot_examples else \"\"\n",
    "        return self.system_prompt_template.format(relation_set_prompt=rsp, few_shot_prompt=fsp)\n",
    "\n",
    "    def _choose_few_shot_examples(self) -> list[dict]:\n",
    "        if len(self.few_shot_examples) <= self.n_few_shot_examples:\n",
    "            return self.few_shot_examples\n",
    "        else:\n",
    "            return np.random.choice(self.few_shot_examples, self.n_few_shot_examples, replace=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = {\n",
    "    \"text\": \"Dead Man's Plack is found in England and is made from rock. The capital of England is London and its religion is Church of England. The British Arabs are an English ethnic group.\",\n",
    "    \"triplets\": [\n",
    "        \"Dead_Man's_Plack | location | England\",\n",
    "        \"England | ethnicGroup | British_Arabs\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "You are helpful assistant that extracts entity-relation-entity triplets from given text.\n",
      "\n",
      "\n",
      "<</SYS>>\n",
      "\n",
      "Dead Man's Plack is found in England and is made from rock. The capital of England is London and its religion is Church of England. The British Arabs are an English ethnic group. [/INST] Dead_Man's_Plack | location | England\n",
      "England | ethnicGroup | British_Arabs\n"
     ]
    }
   ],
   "source": [
    "erx_formatter = ERXFormatter()\n",
    "print(erx_formatter.format_for_train(example)['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "<s>[INST] <<SYS>>\n",
      "You are helpful assistant that extracts entity-relation-entity triplets from given text.\n",
      "\n",
      "Use the same format for triplets as in the examples provided below.\n",
      "# Text\n",
      "London is capital city of UK\n",
      "# Triplets\n",
      "London | capital of | UK\n",
      "\n",
      "<</SYS>>\n",
      "\n",
      "Moscow is capital city of Russia [/INST] Moscow | capital of | Russia\n",
      "================================================================================\n",
      "<s>[INST] <<SYS>>\n",
      "You are helpful assistant that extracts entity-relation-entity triplets from given text.\n",
      "\n",
      "Use the same format for triplets as in the examples provided below.\n",
      "# Text\n",
      "Paris is capital city of France\n",
      "# Triplets\n",
      "Paris | capital of | France\n",
      "\n",
      "<</SYS>>\n",
      "\n",
      "Moscow is capital city of Russia [/INST] Moscow | capital of | Russia\n",
      "================================================================================\n",
      "<s>[INST] <<SYS>>\n",
      "You are helpful assistant that extracts entity-relation-entity triplets from given text.\n",
      "\n",
      "Use the same format for triplets as in the examples provided below.\n",
      "# Text\n",
      "London is capital city of UK\n",
      "# Triplets\n",
      "London | capital of | UK\n",
      "\n",
      "<</SYS>>\n",
      "\n",
      "Moscow is capital city of Russia [/INST] Moscow | capital of | Russia\n"
     ]
    }
   ],
   "source": [
    "few_shot_examples = [\n",
    "    {\n",
    "        \"text\": \"Ankara is capital city of Turkey\",\n",
    "        \"triplets\": [\n",
    "            \"Ankara | capital of | Turkey\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Paris is capital city of France\",\n",
    "        \"triplets\": [\n",
    "            \"Paris | capital of | France\",\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"London is capital city of UK\",\n",
    "        \"triplets\": [\n",
    "            \"London | capital of | UK\",\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "example = {\n",
    "    \"text\": \"Moscow is capital city of Russia\",\n",
    "    \"triplets\": [\n",
    "        \"Moscow | capital of | Russia\",\n",
    "    ],\n",
    "}\n",
    "erx_formatter = ERXFormatter(few_shot_examples=few_shot_examples, n_few_shot_examples=1)\n",
    "for i in range(3):\n",
    "    print(\"=\"*80)\n",
    "    print(erx_formatter.format_for_train(example)['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
