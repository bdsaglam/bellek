{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "import os\n",
    "import re\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from collections import Counter\n",
    "\n",
    "def most_common(lst):\n",
    "    \"\"\"returns the most common element of a collection\"\"\"\n",
    "    return Counter(lst).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "test_eq(most_common([1,1,1,2,2,3,3,3,3,4,4]), 3)\n",
    "test_eq(most_common([1,1,1,2,2,3,3,3,4,4]), 1)\n",
    "test_eq(most_common([0]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "@patch\n",
    "def ls_sorted(self:Path):\n",
    "    \"ls but sorts files by name numerically\"\n",
    "    return self.ls().sorted(key=lambda f: int(f.with_suffix('').name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "# ref: https://dev.to/teckert/changing-directory-with-a-python-context-manager-2bj8\n",
    "@contextmanager\n",
    "def context_chdir(path: Union[Path, str]):\n",
    "    \"\"\"Sets the cwd within the context\"\"\"\n",
    "    origin = Path().absolute()\n",
    "    try:\n",
    "        os.chdir(path)\n",
    "        yield\n",
    "    finally:\n",
    "        os.chdir(origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "origin = os.getcwd()\n",
    "with context_chdir('/opt'):\n",
    "    test_eq(os.getcwd(), '/opt')\n",
    "test_eq(os.getcwd(), origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_time_id(dt=None):\n",
    "    \"\"\"generates a string id from given datetime or now\"\"\"\n",
    "    return (dt or datetime.now()).isoformat().rsplit('.', 1)[0].replace(':', '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "\n",
    "test_eq(generate_time_id(datetime(2022, 1, 1, 1, 1, 1)), '2022-01-01T01-01-01')\n",
    "\n",
    "time_id = generate_time_id()\n",
    "test_eq(len(time_id), 19)\n",
    "test_eq(time_id.count('-'), 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested dictionary utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def flatten_dict(d: Dict, sep='.') -> Dict:\n",
    "    records = pd.json_normalize(d, sep=sep).to_dict(orient='records')\n",
    "    if len(records):\n",
    "        return records[0]\n",
    "    return {}\n",
    "\n",
    "def unflatten_dict(d: Dict, sep='.') -> Dict:\n",
    "    res = {}\n",
    "    for k, v in d.items():\n",
    "        subkeys = k.split(sep)\n",
    "        container = res\n",
    "        for subkey in subkeys[:-1]:\n",
    "            if subkey not in container:\n",
    "                container[subkey] = {}\n",
    "            container = container[subkey]\n",
    "        container[subkeys[-1]] = v\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "\n",
    "noop_cases = [{}, {'a': 1, 'b': 2}]\n",
    "for d in noop_cases:\n",
    "    test_eq(flatten_dict(d), d)\n",
    "    test_eq(unflatten_dict(d), d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "\n",
    "nested_dict = {\n",
    "    'dataset_path': 'a/b/c/d',\n",
    "    'train': {\n",
    "        'lr': 1e-4,\n",
    "        'n_epoch': 10,\n",
    "        'early_stop': {\n",
    "            'patience': 10,\n",
    "            'metric': 'val_loss',\n",
    "        }\n",
    "    },\n",
    "    'wandb': {\n",
    "        'username': 'bdsaglam',\n",
    "        'project': 'project-x',\n",
    "    }\n",
    "}\n",
    "\n",
    "flat_dict = {\n",
    "    'dataset_path': 'a/b/c/d',\n",
    "    'train/lr': 0.0001,\n",
    "    'train/n_epoch': 10,\n",
    "    'train/early_stop/patience': 10,\n",
    "    'train/early_stop/metric': 'val_loss',\n",
    "    'wandb/username': 'bdsaglam',\n",
    "    'wandb/project': 'project-x',\n",
    "}\n",
    "\n",
    "test_eq(flatten_dict(nested_dict, sep='/'), flat_dict)\n",
    "test_eq(unflatten_dict(flat_dict, sep='/'), nested_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class NestedDict(dict):\n",
    "    def __init__(self, data, sep='.'):\n",
    "        super().__init__(data)\n",
    "        self.sep = sep\n",
    "    \n",
    "    def at(self, keys: Union[str, List, Tuple], default=None):\n",
    "        if isinstance(keys, str):\n",
    "            keys = keys.split(self.sep)\n",
    "        node = self\n",
    "        for key in keys:\n",
    "            if key not in node:\n",
    "                return default\n",
    "            node = node.get(key)\n",
    "        return node\n",
    "\n",
    "    def set(self, keys: Union[str, List, Tuple], value):\n",
    "        if isinstance(keys, str):\n",
    "            keys = keys.split(self.sep)\n",
    "        node = self\n",
    "        last_key = keys.pop()\n",
    "        for key in keys:\n",
    "            if key not in node:\n",
    "                node[key] = dict()\n",
    "            node = node[key]\n",
    "        node[last_key] = value\n",
    "\n",
    "    def flat(self) -> Dict:\n",
    "        return flatten_dict(self, sep=self.sep)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_flat_dict(cls, data, sep='.'):\n",
    "        return cls(unflatten_dict(data, sep=sep))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "nested_dict = NestedDict(nested_dict, sep='.')\n",
    "\n",
    "test_eq(nested_dict.at('wandb'), nested_dict['wandb'])\n",
    "test_eq(nested_dict.at(['wandb']), nested_dict['wandb'])\n",
    "test_eq(nested_dict.at('wandb.username'), 'bdsaglam')\n",
    "test_eq(nested_dict.at(['train', 'lr']), nested_dict['train']['lr'])\n",
    "test_eq(nested_dict.at('a.b.c'), None)\n",
    "test_eq(nested_dict.at('train.non-existing-field'), None)\n",
    "test_eq(nested_dict.at('train.non-existing-field', 0), 0)\n",
    "\n",
    "nested_dict.set('dataset_path', '/newpath')\n",
    "test_eq(nested_dict.at('dataset_path'), '/newpath')\n",
    "nested_dict.set('train.lr', 1)\n",
    "test_eq(nested_dict.at('train.lr'), 1)\n",
    "nested_dict.set('train.optimizer.name', 'adam')\n",
    "nested_dict.set('train.optimizer.momentum', 0.9)\n",
    "test_eq(nested_dict.at('train.optimizer.name'), 'adam')\n",
    "test_eq(nested_dict.at('train.optimizer.momentum'), 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "nested_dict = NestedDict.from_flat_dict({'a/b/c': 1, 'd': 2}, sep='/')\n",
    "test_eq(dict(nested_dict), {'a': {'b': {'c': 1}}, 'd': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def split_camel_case(input_str):\n",
    "    # Use regular expression to find word boundaries in camel case\n",
    "    matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', input_str)\n",
    "    # Extract the words and return as a list\n",
    "    return [m.group(0) for m in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(split_camel_case(\"camelCase\"), [\"camel\", \"Case\"])\n",
    "test_eq(split_camel_case(\"CamelCase\"), [\"Camel\", \"Case\"])\n",
    "test_eq(split_camel_case(\"camel\"), [\"camel\"])\n",
    "test_eq(split_camel_case(\"Camel\"), [\"Camel\"])\n",
    "test_eq(split_camel_case(\"\"), [])\n",
    "test_eq(split_camel_case(\"snake_case\"), [\"snake_case\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
