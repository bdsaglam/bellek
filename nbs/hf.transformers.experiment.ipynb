{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers utils for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp hf.transformers.experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from fastcore.test import *\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from bellek.utils import NestedDict, generate_time_id\n",
    "from bellek.logging import get_logger\n",
    "\n",
    "log = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "def preprocess_config(config: NestedDict):\n",
    "    config = deepcopy(config)\n",
    "\n",
    "    # Set float precision\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        log.info(\"GPU supports bfloat16.\")\n",
    "        torch_dtype, bf16, fp16, bnb_4bit_compute_dtype = (\"bfloat16\", True, False, \"bfloat16\")\n",
    "    else:\n",
    "        log.info(\"GPU does not support bfloat16.\")\n",
    "        torch_dtype, bf16, fp16, bnb_4bit_compute_dtype = (\"float16\", False, True, \"float16\")\n",
    "\n",
    "    if config.at(\"pretrained_model.torch_dtype\"):\n",
    "        config.set(\"pretrained_model.torch_dtype\", torch_dtype)\n",
    "    if config.at(\"pretrained_model.quantization_config.load_in_4bit\"):\n",
    "        config.set(\"pretrained_model.quantization_config.bnb_4bit_compute_dtype\", bnb_4bit_compute_dtype)\n",
    "    if config.at(\"trainer.training_args.bf16\") or config.at(\"trainer.training_args.fp16\"):\n",
    "        config.set(\"trainer.training_args.bf16\", bf16)\n",
    "        config.set(\"trainer.training_args.fp16\", fp16)\n",
    "\n",
    "    # Generate unique model id\n",
    "    model_id = config.at(\"hfhub.model_id\")\n",
    "    if config.at(\"trainer.lora\"):\n",
    "        model_id += \"-peft\"\n",
    "    if \"debug\" not in model_id:\n",
    "        model_id += f\"-{generate_time_id()}\"\n",
    "    config.set(\"hfhub.model_id\", model_id)\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
