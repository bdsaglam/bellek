stages:
  answer-questions:
    cmd: >-
      python answer_questions.py
      --dataset-file ../../data/raw/research-mhqa-evaluation/dataset.jsonl
      --out ../../data/generated/research-mhqa-evaluation/qa-results/
      --subset ${dataset.subset}
      --prompt ${prompt}
      --model ${model}
      --temperature ${temperature}
    deps:
      - answer_questions.py
      - ../../data/raw/research-mhqa-evaluation/dataset.jsonl
    outs:
      - ../../data/generated/research-mhqa-evaluation/qa-results/
    params:
      - prompt
      - model
      - temperature
      - run
  
  evaluate-answers:
    cmd: >-
      python evaluate_answers.py
      --dataset-file ../../data/raw/research-mhqa-evaluation/dataset.jsonl
      --qa-dir ../../data/generated/research-mhqa-evaluation/qa-results/
      --out ../../data/generated/research-mhqa-evaluation/evals/
    deps:
      - evaluate_answers.py
      - ../../data/raw/research-mhqa-evaluation/dataset.jsonl
      - ../../data/generated/research-mhqa-evaluation/qa-results/
    outs:
      - ../../data/generated/research-mhqa-evaluation/evals/

  report:
    cmd: >-
      python report.py
      --dataset-file ../../data/raw/research-mhqa-evaluation/dataset.jsonl
      --qa-dir ../../data/generated/research-mhqa-evaluation/qa-results/
      --evals-dir ../../data/generated/research-mhqa-evaluation/evals/
      --out ../../data/generated/research-mhqa-evaluation/reports/
    deps:
      - report.py
      - ../../data/raw/research-mhqa-evaluation/dataset.jsonl
      - ../../data/generated/research-mhqa-evaluation/qa-results/
      - ../../data/generated/research-mhqa-evaluation/evals/
    outs:
      - ../../data/generated/research-mhqa-evaluation/reports/results.jsonl
    metrics:
      - ../../data/generated/research-mhqa-evaluation/reports/scores.json
